{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b1bca3-5989-40f3-b3e1-24b7dcb62220",
   "metadata": {},
   "source": [
    "# Problem 1:\n",
    "\n",
    "Test the following sequence of numbers for uniformity and independence, using Chi-square test and runs-up test, respectively. Use the level of significance α = 0.05.\n",
    "\n",
    "0.594; 0.928; 0.515; 0.055; 0.507; 0.351; 0.262; 0.797; 0.788; 0.422;\n",
    "0.097; 0.798; 0.277; 0.127; 0.474; 0.825; 0.007; 0.182; 0.929; 0.852;\n",
    "0.017; 0.908; 0.301; 0.417; 0.404; 0.830; 0.017; 0.121; 0.905; 0.857"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fbd8c2-82fb-4b84-9dcc-2750901ced6f",
   "metadata": {},
   "source": [
    "<i>Your answer below: Write out the detailed test steps, and your conclusion.</i>\n",
    "\n",
    "### Chi-square Test\n",
    "We propose the following hypotheses to test:\n",
    "- $H_0$: The numbers are uniformly distributed in $(0, 1)$\n",
    "- $H_1$: The numbers are not uniformly distributed in $(0, 1)$\n",
    "\n",
    "<p>\n",
    "First we can divide the interval $(0, 1)$ into $k = 10$ equal subintervals:\n",
    "\n",
    "|Interval    |       Data in interval             | Frequency ($O_i$) |\n",
    "|------------|:----------------------------------:|----------:|\n",
    "| (0, 0.1]   | 0.007, 0.017, 0.017, 0.055, 0.097  | 5         |\n",
    "|(0.1, 0.2]  | 0.121, 0.127, 0.182                | 3         |\n",
    "|(0.2, 0.3]  | 0.262, 0.277                       | 2         |\n",
    "|(0.3, 0.4]  | 0.301, 0.351                       | 2         |\n",
    "|(0.4, 0.5]  | 0.404, 0.417, 0.422, 0.474         | 4         |\n",
    "|(0.5, 0.6]  | 0.507, 0.515, 0.594                | 3         |\n",
    "|(0.6, 0.7]  |                                    | 0         |\n",
    "|(0.7, 0.8]  | 0.788, 0.797, 0.798                | 3         |\n",
    "|(0.8, 0.9]  | 0.825, 0.83, 0.852, 0.857          | 4         |\n",
    "|(0.9, 1.0]  | 0.905, 0.908, 0.928, 0.929         | 4         |\n",
    "\n",
    "The expected frequency of each interval is $E_i = \\frac{n}{k} = \\frac{30}{10} = 3$.\n",
    "\n",
    "The chi-squared statistic can be calculated as:<br>\n",
    "$\\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i-E_i)^2}{E_i} = \\frac{1}{3}((5-3)^2 + 3(4-3)^2 + 3(3-3)^2 + 2(2-3)^2 + (0-3)^2)$\n",
    "\n",
    "Calculating each term gives:<br>\n",
    "$\\chi^2 = 1.333 + 0.000 +0.333 +0.333+0.333+0+3.00+0.000+0.333+0.333= 5.998 \\approx 6.0$\n",
    "\n",
    "The degrees of freedom are $k − 1 = 10-1 = 9$. From the Chi-square distribution table, the critical value for\n",
    "$\\alpha = 0.05$ and 9 degrees of freedom is $\\chi^2_{0.05, 9} = 16.92$. Since the computed value $6.0 < 16.92$, $H_0$ is not rejected. Thus, there is no statistical evidence to reject the assumption that the generated numbers are uniformly distributed in $(0, 1)$ at the $5\\%$ significance level.\n",
    "\n",
    "### Runs-up test\n",
    "<p>\n",
    "We propose the following hypotheses to test:\n",
    "    \n",
    "- $H_0$: The numbers are independent and uniformly distributed in $(0, 1)$\n",
    "- $H_1$: The numbers are not independent and uniformly distributed in $(0, 1)$\n",
    "  \n",
    "A run-up is defined as a consecutive sequence of numbers in which each number is larger than the previous\n",
    "one. The run-ups of the provided data set are: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$(0.594, 0.928), (0.515), (0.055, 0.507), (0.351), (0.262, 0.797), (0.788), (0.422), (0.097, 0.798), (0.277), (0.127, 0.474, 0.825),$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$(0.007, 0.182, 0.929),(0.852), (0.017, 0.908), (0.301, 0.417), (0.404, 0.830), (0.017, 0.121, 0.905), (0.857)$<br>\n",
    "so there are $R=17$ run-ups in total.\n",
    "\n",
    "We can calculate the expectation value and variance of the number of run-ups respectively by<br> \n",
    "$E[R] = \\frac{(2n - 1)}{3} = \\frac{(59)}{3} \\approx 19.67$<br>\n",
    "$Var[R] = \\frac{(16n - 29)}{90} = \\frac{(479)}{3} \\approx 5.01$\n",
    "\n",
    "The test statistic is calculated by<br>\n",
    "$Z = \\frac{R-E[R]}{\\sqrt{Var[R]}} = \\frac{17-19.67}{\\sqrt{5.01}} = \\frac{-2.66}{2.24}\\approx-1.19$<br>\n",
    "\n",
    "For a two-tailed test at the $5\\%$ significance level, the critical values are $\\pm1.96$. Since $|Z| = 1.19 < 1.96$, we fail to reject $H_0$. Thus, there is no statistical evidence to reject the assumption that the generated numbers are independent at the $5\\%$ significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5393d448-21d8-48fc-8a76-cdf9618df2ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''This is just for me to check the math'''\n",
    "import numpy as np\n",
    "\n",
    "data = [0.594, 0.928, 0.515, 0.055, 0.507, 0.351, 0.262, 0.797, 0.788, 0.422, 0.097, 0.798, 0.277, 0.127, 0.474, \\\n",
    "            0.825, 0.007, 0.182, 0.929, 0.852, 0.017, 0.908, 0.301, 0.417, 0.404, 0.830, 0.017, 0.121, 0.905, 0.857]\n",
    "\n",
    "def get_runs_up():\n",
    "    runs_up = 0\n",
    "    last_val = 0\n",
    "    indexes = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if  not (data[i] >= last_val):\n",
    "            last_val = 0\n",
    "            runs_up += 1\n",
    "            indexes.append(i-1)\n",
    "\n",
    "        last_val = data[i]\n",
    "    \n",
    "    return runs_up + 1, indexes\n",
    "\n",
    "def runs_up_test():\n",
    "    R, _= get_runs_up()\n",
    "    ER = (2*len(data) - 1)/3\n",
    "    VarR = (16*len(data) - 29)/90\n",
    "    Z = (R-ER)/np.sqrt(VarR)\n",
    "\n",
    "    Z_crit = 1.96 #two-tailed test with alpha = 0.05\n",
    "\n",
    "    print(f'Since {abs(Z):.3f} < {Z_crit}, H0 is not rejected.')\n",
    "\n",
    "\n",
    "def chi_square_test(): \n",
    "    data.sort()\n",
    "    \n",
    "    a = 0.05\n",
    "    k = 10\n",
    "    \n",
    "    #intervals: (0,0.1], (0.1,0.2], (0.2,0.3], (0.3,0.4], (0.4,0.5], (0.5,0.6], (0.6,0.7], (0.7,0.8], (0.8,0.9], (0.9,1.0]\n",
    "    data_intervals = [data[0:5], data[5:8], data[8:10], data[10:12], data[12:16], data[16:19], [], data[19:22], data[22:26], data[26:30]]\n",
    "    Oi = [len(data_intervals[i]) for i in range(k)]\n",
    "    Ei = len(data)/k\n",
    "    \n",
    "    chi_square = 0\n",
    "    for i in range(k):\n",
    "        chi_square += ((Oi[i] - Ei)**2 / Ei)\n",
    "    \n",
    "    deg_free = k-1\n",
    "    chi_table = 16.919\n",
    "    \n",
    "    print(f'Since {chi_square:.3f} < {chi_table}, H0 is not rejected.')\n",
    "    return data_intervals\n",
    "\n",
    "#runs_up_test()\n",
    "#intervals = chi_square_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e49114",
   "metadata": {},
   "source": [
    "# End of Problem 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442175a6-5825-4d64-95de-af6e26b61dfe",
   "metadata": {
    "id": "e20440a1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Problem 2\n",
    "\n",
    "Use the inverse-transform method to develop a random-variate generator for a random variable $X$ with the pdf\n",
    "\n",
    "$$\n",
    "f(x) = \n",
    "\\begin{cases} \n",
    "0, & x<a \\\\\n",
    "\\frac{2(x-a)}{(b-a)(c-a)}, & a \\leq x \\leq c  \\\\\n",
    "\\frac{2(b-x)}{(b-a)(b-c)}, & c \\leq x \\leq b  \\\\\n",
    "0, & x>b \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Ans: Note that you only need to write out the math. derivation steps and the final pseudocode. No need to write program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7328024-bc8e-44f8-9a48-fa6a2715a8b9",
   "metadata": {
    "id": "e20440a1"
   },
   "source": [
    "Derive the CDF:<br>\n",
    "\n",
    "1. $F(x) = \\int_{-\\infty}^x 0 dt = 0$\n",
    "2. $F(x) = \\int_a^x \\frac{2(t-a)}{(b-a)(c-a)}  dt = \\frac{2}{(b-a)(c-a)}(\\frac{1}{2}t^2-at)|_a^x = \\frac{x^2-2ax+a^2}{(b-a)(c-a)}= \\frac{(x-a)^2}{(b-a)(c-a)}$\n",
    "3. $F(x) = \\int_c^x \\frac{2(b-t)}{(b-a)(b-c)}  dt = \\frac{2}{(b-a)(b-c)}(bt-\\frac{1}{2}t^2)|_c^x = \\frac{(2bx-x^2+c^2-2bc)}{(b-a)(b-c)} = \\frac{(b-x)^2-(b-c)^2}{(b-a)(b-c)} = 1-\\frac{(b-x)^2}{(b-a)(b-c)}$\n",
    "4. $F(x) = \\int_b^\\infty 0 dt = 0$\n",
    "\n",
    "Let $U$ be a uniform random variable in $(0, 1)$. According to the inverse-tansform method, $F(X) = U$. Substituting into the derived CDF gives:\n",
    "\n",
    "2. $\\frac{(x-a)^2}{(b-a)(c-a)} = U$\n",
    "3. $1-\\frac{(b-x)^2}{(b-a)(b-c)} = U$\n",
    "\n",
    "We can solve these expressions for $X$:\n",
    "\n",
    "2. $\\frac{(X-a)^2}{(b-a)(c-a)} = U \\rightarrow X = a\\pm\\sqrt{U(b-a)(c-a)}$<br>\n",
    "   Since $X\\geq a$, choose: $X = a+\\sqrt{U(b-a)(c-a)}$\n",
    "   \n",
    "3. $1-\\frac{(b-x)^2}{(b-a)(b-c)} = U \\rightarrow X = b\\pm\\sqrt{(1-U)(b-a)(b-c)} = b\\pm\\sqrt{U(b-a)(b-c)}$ since $U$ and $1−U$ are identically distributed as Uniform(0, 1)<br>\n",
    "   Since $X\\leq b$, choose: $X = b-\\sqrt{U(b-a)(b-c)}$\n",
    "\n",
    "Since the provided PDF is piecewise, we need to find the boundary point where it switches between the two derived expressions for X. On the boundary, both expressions will produce the same result. Using the derived CDF, the boundary probability is $F(c) = \\frac{(c-a)^2}{(b-a)(c-a)} = \\frac{(c-a)}{(b-a)}$\n",
    "\n",
    "So the pseudocode algorithm would be:\n",
    "\n",
    "<span style=\"font-family: 'Courier New'\">\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate U ~ Uniform(0,1)<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if U < ((c - a)/(b - a)) then<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X = a + sqrt(U * (b - a) * (c - a))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X = b - sqrt(U * (b - a) * (b - c))<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return X<br>\n",
    "</span>\n",
    "\n",
    "# End of Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e07b1",
   "metadata": {
    "id": "0b5e07b1"
   },
   "source": [
    "# Problem 3\n",
    "\n",
    "\n",
    "Assume we need input data to drive a supply-chain management simulation. In this simulation, two correlated random variables must be generated: $X_1$ representing the lead time and $X_2$ representing the monthly demand. \n",
    "\n",
    "The marginal distributions of the two variables are specified as\n",
    "$$\n",
    "X_1 \\sim \\mathrm{Exp}(\\lambda = 5), \\qquad\n",
    "X_2 \\sim \\mathrm{Uniform}[1, 10],\n",
    "$$\n",
    "and their desired correlation is given by\n",
    "$$\n",
    "\\rho_X = \\mathrm{Corr}(X_1, X_2)\n",
    "= \\frac{\\mathrm{Cov}(X_1, X_2)}{\\sqrt{\\mathrm{Var}(X_1)\\,\\mathrm{Var}(X_2)}} = 0.7.\n",
    "$$\n",
    "\n",
    "Write Python code that applies the NORTA (Normal-to-Anything) technique to generate 1000 correlated $(X_1, X_2)$ samples. Your code should address the following questions:\n",
    "\n",
    "(1) Using $\\rho_Z = 0.7$ as the initial Gaussian correlation, what is the corresponding sample correlation $\\rho_X$ obtained from the 1000 generated samples?\n",
    "\n",
    "(2) If fine-tuning is necessary, what value of $\\rho_Z$ should be used to achieve $\\rho_X = 0.7\\pm 0.01$?\n",
    "\n",
    "(3) Determine the possible range of $\\rho_X$ by setting $\\rho_Z = -0.999$ and $\\rho_Z = 0.999$ in the NORTA procedure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2d78d61b-6ca9-4dc1-b284-76e3ee4d0fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 1: px = 0.585 for pz = 0.7\n",
      "PART 2: To achieve px = 0.7±0.01, pz = 0.820 is needed (for px = 0.702)\n",
      "PART 3: px range = [-0.873, 0.879], achievable when pz = [-0.999, 0.999]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "np.random.seed(3)\n",
    "\n",
    "def norta(pz, n):\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, pz], [pz, 1]]\n",
    "    Z1, Z2 = np.random.multivariate_normal(mean, cov, size=n).T\n",
    "\n",
    "    X1, X2 = get_correlatedX(Z1, Z2)\n",
    "\n",
    "    return X1, X2\n",
    "\n",
    "def get_correlatedX(Z1, Z2):\n",
    "    U1 = norm.cdf(Z1) #standard normal cdf\n",
    "    U2 = norm.cdf(Z2)\n",
    "\n",
    "    X1 = -np.log(1-U1)/5\n",
    "    X2 = 1 + U2*9 \n",
    "\n",
    "    return X1, X2\n",
    "\n",
    "def get_px(X1, X2):\n",
    "    mean_x1 = np.mean(X1)\n",
    "    mean_x2 = np.mean(X2)\n",
    "    n = len(X1)\n",
    "\n",
    "    cov_sum = 0       #Cov(X1, X2)\n",
    "    var_sum_x1 = 0    #Var(X1)\n",
    "    var_sum_x2 = 0    #Var(X2)\n",
    "\n",
    "    #find the covariance and variance of X1, X2\n",
    "    for i in range(n):\n",
    "        cov_sum += (X1[i]-mean_x1)*(X2[i]-mean_x2)\n",
    "        var_sum_x1 += (X1[i]-mean_x1)**2\n",
    "        var_sum_x2 += (X2[i]-mean_x2)**2\n",
    "\n",
    "    cov_sum = cov_sum/(n-1)\n",
    "    var_sum_x1 = var_sum_x1/(n-1)\n",
    "    var_sum_x2 = var_sum_x2/(n-1)\n",
    "    \n",
    "    px = cov_sum / np.sqrt(var_sum_x1 * var_sum_x2)\n",
    "    return px\n",
    "\n",
    "def bisec_fine_tune(target_px, tol, n):\n",
    "    \n",
    "    #fix a single stream of base normals\n",
    "    W1 = np.random.standard_normal(n) \n",
    "    W2 = np.random.standard_normal(n)\n",
    "\n",
    "    #partition range\n",
    "    l, u = -0.99, 0.99\n",
    "\n",
    "    while True:\n",
    "        m = (l + u)/2\n",
    "        Z1 = W1\n",
    "        Z2 = m*W1 + np.sqrt(1 - m**2)*W2\n",
    "        \n",
    "        X1, X2 = get_correlatedX(Z1, Z2)\n",
    "        trial_px = get_px(X1, X2)\n",
    "\n",
    "        #return if calculated px within tolerance, else adjust partition\n",
    "        if (trial_px >= target_px-tol) and (trial_px<=target_px+tol):\n",
    "            return trial_px, m\n",
    "        elif trial_px < target_px:\n",
    "            l = m\n",
    "        else:\n",
    "            u = m\n",
    "\n",
    "'''______________________________________________________________________________________________________________________'''\n",
    "\n",
    "n = 1000\n",
    "\n",
    "#Part 1\n",
    "pz_1 = 0.7\n",
    "X1_1, X2_1 = norta(pz_1, n)\n",
    "px_1 = get_px(X1_1, X2_1)\n",
    "print(f'PART 1: px = {px_1:.3f} for pz = {pz_1}')\n",
    "\n",
    "#Part 2\n",
    "target_px = 0.7\n",
    "tolerance = 0.01\n",
    "accept_px, trial_pz = bisec_fine_tune(target_px, tolerance, n)\n",
    "print(f'PART 2: To achieve px = {target_px}±{tolerance}, pz = {trial_pz:.3f} is needed (for px = {accept_px:.3f})')\n",
    "\n",
    "#Part 3\n",
    "pz_3 = [-0.999, 0.999]\n",
    "X1_min, X2_min = norta(pz[0], n)\n",
    "X1_max, X2_max = norta(pz[1], n)\n",
    "px_min = get_px(X1_min, X2_min)\n",
    "px_max = get_px(X1_max, X2_max)\n",
    "print(f'PART 3: px range = [{px_min:.3f}, {px_max:.3f}], achievable when pz = [-0.999, 0.999]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec549d7",
   "metadata": {},
   "source": [
    "<i>Provide a clear and detailed guide below on how to run your program, including all necessary steps and input parameters, so that the TA can execute your code and verify the results for the three questions described above.</i>\n",
    "\n",
    "The code to output the results for each of the three questions occurs belows the '''_______''' comment, and it has been clearly labelled with a comment listing which question/part it's for. All input parameters have been placed near the top of their respective sections for ease of access. To run all the parts of the questions again, run the entire cell again. \n",
    "\n",
    "Here is a description of the variables that can be changed to adjust the input parameters:\n",
    "\n",
    "1. <u>Part 1</u>: <b>pz_1</b> - the trial correlation $\\rho_z$, currently set for $\\rho_z = 0.7$ as specified in description of (1)\n",
    "2. <u>Part 2</u>: <b>target_px</b> - the desired correlation $\\rho_x$, currently set for $\\rho_x = 0.7$ as specified in description of (2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>tolerance</b> - the absolute value of the tolerance (eg. $0.01$ from $0.7\\pm0.01$), currently set for $0.01$ as specified in description of (2)\n",
    "3. <u>Part 3</u>: <b>pz_3</b> - an array of \\[min $\\rho_z$, max $\\rho_z$\\], current set for \\[$-0.999, 0.999$\\] as specified in description of (3)\n",
    "\n",
    "The program to run generate $X1$ and $X2$ according the provided distributions is <span style=\"font-family: 'Courier New'\">norta($\\rho_z$, number of samples)</span>, which can be run by adding a line of code calling the function directly or by running the code under the part 1 header with $X1$, $X2$ being the resulting correlated samples.\n",
    "\n",
    "The seed for the random variables is set at the top of the code block to $3$. This can also be changed to get different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9ca6b",
   "metadata": {},
   "source": [
    "\n",
    "# End of Problem 3"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
